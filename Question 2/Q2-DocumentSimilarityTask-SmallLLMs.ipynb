{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vsg2I4D3ibwx"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXg86AmcjK9p"
   },
   "source": [
    "# Instantiating the function for document similarity computation using embeddings from a LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o_sBcFvUigQd"
   },
   "outputs": [],
   "source": [
    "def compare_documents(doc1, doc2):\n",
    "\n",
    "    # Tokenize and encode the documents\n",
    "    encoding1 = embedding_tokenizer(doc1, return_tensors='pt', truncation=True,max_length=200)\n",
    "    encoding2 = embedding_tokenizer(doc2, return_tensors='pt', truncation=True,max_length=200)\n",
    "\n",
    "    # Compute model scores\n",
    "    with torch.no_grad():\n",
    "        outputs1 = embedding_model(**encoding1)\n",
    "        outputs2 = embedding_model(**encoding2)\n",
    "\n",
    "    embeddings1 = outputs1.last_hidden_state.mean(dim=1)\n",
    "    embeddings2 = outputs2.last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Compare the scores\n",
    "    similarity_score = cosine_similarity(embeddings1, embeddings2)[0][0]\n",
    "\n",
    "    return similarity_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja7oXMysjqQf"
   },
   "source": [
    "# Sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dQBjWQ4Vilc-"
   },
   "outputs": [],
   "source": [
    "doc1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "doc2 = \"A lazy dog is jumped over by a quick brown fox.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUWWbIDyjsDl"
   },
   "source": [
    "# Model 1 - distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEVYmrGgjYZS",
    "outputId": "17d26bf9-f440-4a2b-98ca-4c8f6b007a93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.9402323\n"
     ]
    }
   ],
   "source": [
    "embedding_model_name = \"distilbert-base-uncased\"\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "\n",
    "embedding_tokenizer.pad_token = embedding_tokenizer.eos_token\n",
    "\n",
    "similarity_score = compare_documents(doc1, doc2)\n",
    "print(\"Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIRX4ZBDjzos"
   },
   "source": [
    "# Model 2 - Writer/palmyra-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8vr7ySKinhg",
    "outputId": "a8702ec2-b161-41b6-cd32-3879fbf5921b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.88224614\n"
     ]
    }
   ],
   "source": [
    "embedding_model_name = \"Writer/palmyra-small\"\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "\n",
    "embedding_tokenizer.pad_token = embedding_tokenizer.eos_token\n",
    "\n",
    "similarity_score = compare_documents(doc1, doc2)\n",
    "print(\"Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yeo5LX9j5k7"
   },
   "source": [
    "# Model 3 - gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFGoa9Tai6Of",
    "outputId": "dd1217f4-3fb1-4977-9c80-6d7e1900e40e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.99865556\n"
     ]
    }
   ],
   "source": [
    "embedding_model_name = \"gpt2\"\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "\n",
    "embedding_tokenizer.pad_token = embedding_tokenizer.eos_token\n",
    "\n",
    "similarity_score = compare_documents(doc1, doc2)\n",
    "print(\"Similarity Score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_UVezCQjDRm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
